# Approaches to Bayesian Computation {#computation}

This chapter describes methods for implementing Bayesian models when their complexity means that simple, analytic solutions may not be available. The reader will have gained an understanding of the following topics:
- analytical approximations to the posterior distribution;
- use of samples from a posterior distribution for inference and Monte Carlo integration;
- methods for direct sampling such as importance and rejection sampling;
- Markov Chain Monte Carlo (MCMC) and methods for obtaining samples from the required posterior distribution including Metropolis--Hastings and Gibbs algorithms;
- use of NIMBLE and RStan packages to fit Bayesian models using Gibbs sampling; 
- Integrated Nested Laplace Approximations (INLA) as a method for performing efficient Bayesian inference including the use of R-INLA to implement a wide variety of latent Gaussian models.


## Example 6.2: Gibbs sampling with a Poisson-Gamma model - hospital admissions for chronic obstructive pulmonary disease (COPD) for England between 2001-2010 {-} 

We now look at example into the hospital admission rates for chronic obstructive pulmonary disease (COPD) in England between 2001–2010. 

In England, there are 324 local authority administrative areas each with an observed and expected number of cases. The expected numbers were calculated using indirect standardization by applying the age–sex specific rates for the whole of England to the age–sex population profile of each of
the areas.


We show the full conditional distributions for a Poisson model where the prior distribution on the rates is Gamma, that is, $y_i \mid \theta_, E_i \sim Poi(\theta_i E_i)$ where $E_i$ is the  expected number of cases in area $i$. In particular, let $\mathbf{y} = (y_1, ..., y_N)$ be a   $N$-dimensional vector with observed counts on  the total number of 
hospital admissions for chronic obstructive pulmonary disease (COPD) for England between 2001 and 2010. The expected numbers of hospital admissions by local authority  were computed as described in Chapter 2, Section 2.1.


If we assign a Gamma prior to the random effects $\theta_i$, i.e., $\theta_i \sim Gamma(a, b)$ for $i=1, \dots N$, and independent exponential distributions to the hyperparameters $a$ and $b$   then we can find the full conditional distributions required for Gibbs sampling. 

The joint  posterior is proportional to

\begin{eqnarray} \nonumber
p(a, b, \mathbf{\theta} | \mathbf{y}) &\propto& \prod^N	_{i=1} \frac{\left(\theta_i E_i\right)^{y_i}}{y_i!} \exp(-\theta_i E_i) \, \frac{b^{a}}{\Gamma (a) }\theta_i^{a-1} e^{-b \theta_i}  \\ \nonumber 
&& \times \lambda_{a} \exp(-\lambda_{a}) \, \lambda_{b}\exp(-\lambda_{b}),
\end{eqnarray}
and the full conditionals are:
\begin{enumerate}
\item Posterior full conditional for each $\theta_i$, $i=1,\dots,N$:
$$
p(\theta_i | \mathbf{\theta}_{-i}, a, b, \mathbf{y}) \propto  \theta_i^{y_i+a-1} \exp[-(E_i+b)\theta_i],
$$
which is the kernel of a Gamma distribution with parameters $y_i+a$ and $E_i+b$;
\item Posterior full conditional for $b$:
$$
p(b | \mathbf{\theta}, a, \mathbf{y}) \propto 
	b^{N a} \exp\left[-\left(\sum^N_{i=1}\theta_i + \lambda_{b}\right)b\right],
$$
which is the kernel of a Gamma distribution with parameters $Na+1$ and $(\sum^N_{i=1}\theta_i + \lambda_{b})$;
\item Posterior full conditional for $a$:
$$
p(a | \mathbf{\theta}, b, \mathbf{y})  \propto  \frac{\left(b^N \prod^N_{i=1}\theta_i\right)^{a-1}}{\Gamma (a)^N },
$$
which does not have a closed form. We propose to sample from $p(a | \mathbf{\theta}, b, \mathbf{y})$ through a random walk, Metropolis-Hastings step. As $a$ must be strictly positive, the proposal is a log-normal distribution whose associated normal distribution has mean at the logarithm of the current value and some fixed variance, say $u$, that needs to be tuned.
\end{enumerate}

For this example, the following packages are needed `ggplot2` and  `sf`. 

Load the necessary packages.

```{r Ex 6.2 prelim load, message=FALSE, echo = TRUE, warning=FALSE}

library(ggplot2)
library(sf)

```

To create SMR maps, we need to read in the relevant shapefiles. 

- [englandlocalauthority.shp](https://github.com/spacetime-environ/stepi2/blob/main/data/copd/englandlocalauthority.shp) and [englandlocalauthority.dbf](https://github.com/spacetime-environ/stepi2/blob/main/data/copd/englandlocalauthority.dbf) contain the location, shape, and attributes of English local authorities. The function `read_sf()` from the `sf` package  will read these shapefiles into `R`.
- [copdmortalityobserved.csv](https://github.com/spacetime-environ/stepi2/blob/main/data/copd/copdmortalityobserved.csv) contains the **observed**  number of hospital admissions in England by local authority. You can find this data by clicking.
- [copdmortalityexpected.csv](https://github.com/spacetime-environ/stepi2/blob/main/data/copd/copdmortalityexpected.csv) contains the **expected** number of hospital admissions in England by local authority. 

```{r Ex 6.2 read files, class.source = 'foldable' }
# Reading in the borders of the shape file
england <- read_sf("data/copd/englandlocalauthority.shp")

# Reading in data
observed <-
  read.csv(file = "data/copd/copdmortalityobserved.csv", row.names = 1)

expected <-
  read.csv(file = "data/copd/copdmortalityexpected.csv", row.names = 1)

```

Print summaries of the observed and expected counts.

```{r Ex 6.2 expected counts, class.source = 'foldable'}

# Printing first six rows of the observed counts
head(observed)

# Printing first six rows of the expected counts
head(expected)

# Summarising the observed counts
summary(observed)

# Summarising the expected counts
summary(expected)

```

### Modelling the raw  standardized mortality rates (SMRs) {-}

Calculate the raw SMRs as.

$$ \text{SMR} = \frac{observed}{expected}$$

```{r Ex 6.2 SMRs}

SMR_raw <- observed[, -1] / expected

# Rename columns
names(SMR_raw) <-
  c(
    "SMR2001",
    "SMR2002",
    "SMR2003",
    "SMR2004",
    "SMR2005",
    "SMR2006",
    "SMR2007",
    "SMR2008",
    "SMR2009",
    "SMR2010"
  )

# Printing first six rows of raw SMRs
head(SMR_raw)

# Summarising raw SMRs
summary(SMR_raw)

```


Attach the values of the raw SMRs to the shapefiles. The function `merge()` allows us to combine a data frame with a shapefile to plot later.

```{r Ex 6.2 combine smr and shapefiles, class.source = 'foldable'}

# Convert row names to ID column
SMR_raw <- tibble::rownames_to_column(SMR_raw, "ID")

# Combine raw SMRs and shapefiles
SMRspatial_raw <- merge(england, SMR_raw, by = "ID") 

```

Use `ggplot()` and `geom_sf()` to create a choropleth map such that local authorities are colored by the raw SMR estimate.

```{r Ex 6.2 map, class.source = 'foldable', fig.align = 'center'}

# Creating breaks for legend in plot
range <-
  seq(min(SMR_raw$SMR2010) - 0.01,
      max(SMR_raw$SMR2010) + 0.01,
      length.out = 11)

# Creating map of Raw SMRs in England in 2010
ggplot() +
  # Choose spatial object and column for plotting
  geom_sf(data = SMRspatial_raw, aes(fill = SMR2010)) + 
  # Break points for colours
  scale_y_continuous(breaks = range) + 
  # Clear background and plot borders
  theme(
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    rect = element_blank()
  ) 

```

### Modelling a Poisson-Gamma with an MCMC implemented in `R` {-}

The following code shows how to implement the MCMC using `R` for the COPD example.

First, the constants are defined and the necessary vectors are initialized. 


```{r Ex 6.2 MCMC const, cache = TRUE }

# observations
y <- observed$Y2010
# offset
E <- expected$E2010
# Number of MCMC iterations
L <- 80000

## Initialize objects used in MCMC
# Matrix for sampled values of parameter theta_i 
theta <-
  matrix(ncol = length(y), nrow = L)
# Matrix for fitted values 
fitted <- theta
# Vector for sampled values of hyper-parameter a
a <- c() 
# Vector for sampled values of hyper-parameter b
b <- c() 

## Define constants
# Sample size
N <- length(y)
# Parameter of exponential prior for a
lambda_a <- 1
# Parameter of exponential prior for b
lambda_b <- 1
# standard deviation of the proposal distribution of log a
u <- 0.5 
# Initialize theta
theta[1, ] <- y / E
# Initial value sampled from the prior for a
# REVIEW: In the example of the book theta ~ Ga(a,a) not Ga(a,b)
a <- rexp(1, lambda_a)
# Initial value sampled from the prior for b
b <- rexp(1, lambda_b) 
fitted[1, ] <- rpois(N, E * theta[1, ])


# Once all the constants and initial values are set we can run the MCMC. 
# The following code shows the MCMC implementation of a Poisson-Gamma model using only `R`.


# Starting from l=2 as l=1 contains the initial values
for(l in 2:L) {

# Sampling from the posterior full conditional of each theta_i
  for (i in 1:N)
    theta[l, i] <- rgamma(1, (y[i] + a[(l - 1)]), rate = (E[i] + b[(l - 1)]))
  # Sampling from the posterior full conditional of b
  b[l] <- rgamma(1, (N * a[(l - 1)] + 1), rate = (sum(theta[l, ]) + lambda_b))
  # Metropolis-Hastings step to sample from the full conditional of "a"
  # the new value receives the current value in case the proposed
  # value is rejected
  a[l] <- a[l - 1]
  # Proposal in the log-scale
  laprop <- rnorm(1, log(a[l - 1]), u)
  aprop <- exp(laprop)
  #computing the numerator of the M-H step
  num <- N * (aprop * (log(b[l])) - lgamma(aprop)) + (aprop - 1) * sum(log(theta[l, ])) -
    aprop * lambda_a + log(aprop)
  #computing the denominator of the M-H step
  den <- N * (a[l - 1] * (log(b[l])) - lgamma(a[l - 1])) +
    (a[(l - 1)] - 1) * sum(log(theta[l, ])) - a[(l - 1)] * lambda_a + log(a[(l - 1)])
  #computing the M-H ratio
  ratio <- exp(num - den)
  unif <- runif(1)
  # Change the current value if the proposed value is accepted
  if (unif < ratio)
    a[l] <- aprop
  fitted[l,] <- rpois(N, E * theta[l,])
}

```

After running the MCMC, we should check if the chains have converged

```{r Ex 6.2 MCMC convergence}

# Number of burn in samples and thinning
burnin <- 20000
thin <- 30
# MCMC samples
seqaux <- seq(burnin, L, by = thin)

# Trace-plots of the parameters
xx <- seq(0, 6, length = 2000)

par(mfrow = c(2, 2))
# Plot for "a"
plot(a[seqaux], type = "l", bty = "n")
hist(a[seqaux], prob = 1, main = "")
lines(xx, dexp(xx, lambda_a), col = 2, lwd = 2)
acf(a[seqaux])
# COMBAK: This chains are not looking great

# Plot for "b"
plot(b[seqaux], type = "l", bty = "n")
hist(b[seqaux], prob = 1, main = "")
lines(xx, dexp(xx, lambda_b), col = 2, lwd = 2)

# Traceplots of theta's

par(mfrow = c(3, 3))
for (i in 1:9)
  plot(theta[seqaux, i], type = "l", bty = "n")

```

<!-- TODO: Add effective size and paragraph about acceptance ratio -->

Given the convergence issues, we can also check the estimated sampled size and Rhat using the package `coda`.

```{r Ex 6.2 ESS and Rhat}

paste0("ESS a: ", coda::effectiveSize(a[seqaux]))
paste0("ESS b: ", coda::effectiveSize(b[seqaux]))
paste0("ESS theta[1]: ", coda::effectiveSize(theta[seqaux, 1]))
paste0("ESS theta[10]: ",coda::effectiveSize(theta[seqaux, 10]))

  
```

The variances for the parameters `a` and `b` is lower than the recommended minimum of 100. We will go back to this in Chapter 8. 

Now that we have guaranteed the convergence of the chains, we can look at the posterior summaries.

```{r Ex 6.2 MCMC posterior summary, fig.align = 'center', fig.align = 'center'}

# Posterior summaries of theta_i
meantheta <- apply(theta, 2, mean)
q025theta <- apply(theta, 2, function(x)
  quantile(x, 0.025))
q975theta <- apply(theta, 2, function(x)
  quantile(x, 0.975))

# Plot the mean and 95% CIs for the thetas

par(mfrow = c(1, 1))
plot(
  meantheta,
  pch = 19,
  cex = 0.8,
  bty = "n",
  xlab = "Borough",
  ylab = "Posterior Summary Rate",
  ylim = c(min(q025theta), max(q975theta))
)
for (i in 1:N)
  segments(i, q025theta[i], i, q975theta[i])
abline(h = 1, lwd = 2, lty = 2)

# Posterior summary of fitted values

meanfit <- apply(fitted, 2, mean)
q025fit <- apply(fitted, 2, function(x)
  quantile(x, 0.025))
q975fit <- apply(fitted, 2, function(x)
  quantile(x, 0.975))

# Plot mean and 95% CIs for the fitted values

par(mfrow = c(1, 1))
plot(
  y,
  meanfit,
  ylim = c(min(q025fit), max(q975fit)),
  xlab = "Observed",
  ylab = "Fitted",
  pch = 19,
  cex = 0.7,
  bty = "n"
)
for (i in 1:N)
  segments(y[i], q025fit[i], y[i], q975fit[i])
abline(a = 0, b = 1)

```


## Example 6.3: Fitting a Poisson regression model {-}
### Nimble {-}

```{r Ex 6.3 nimble clean, echo = FALSE, include=FALSE, warning=FALSE, message= FALSE, results='hide'}

rm(list=ls())

```

Load `nimble package`

```{r Ex 6.3 nimble prelim load, class.source = 'foldable', message=FALSE, echo = TRUE, warning=FALSE}

library("nimble")

```


The following code is used to fit the Poisson log-linear model seen in Chapter 2 Section ... using `Nimble`

First, define the model in Nimble. 

```{r Ex 6.3 model nimble, results='hide', results='hide', message = FALSE, warning = FALSE, cache = TRUE}

# Define the model 
Example5_3Code <- nimbleCode({
  for (i in 1:N) {
    Y[i] ~ dpois(mu[i])
    log(mu[i]) <- log(E[i]) + beta0 + beta1 * X1[i] + beta2 * X2[i]
  }
  
  # Priors
  beta0 ~ dnorm (0 , sd = 100)
  beta1 ~ dnorm (0 , sd = 100)
  beta2 ~ dnorm (0 , sd = 100)
  
  # Functions of interest:
  base <- exp(beta0)
  RR <- exp(beta1)
})

# Read the data and define the constants, data and initials lists for the `Nimble` model.

# REVIEW: Is this another version of the COPD data? Is there a data dictionary for this dataset?

data <- read.csv("data/DataExample53.csv", sep = ",")

ex.const <- list(
  N = nrow(data),
  E = data$exp_lungc65pls,
  X1 = as.vector(scale(data$k3)),
  X2 = as.vector(scale(data$k2))
)

ex.data <- list(Y = data$lungc65pls)

inits <- function()
  list(beta0 = rnorm(1),
       beta1 = rnorm(1),
       beta2 = rnorm(1))

# Define parameters to monitor and run the model

params <- c("beta0", "beta1", "beta2", "base", "RR")

mcmc.out <- nimbleMCMC(
  code = Example5_3Code,
  data = ex.data,
  constants = ex.const,
  inits = inits,
  monitors = params,
  niter = 22000,
  nburnin = 2000,
  thin = 10,
  WAIC = TRUE,
  nchains = 2,
  samplesAsCodaMCMC = TRUE
)

```



Check the WAIC. 

```{r Ex 6.3 nimble WAIC}

mcmc.out$WAIC

```

Show the trace plots and posterior summaries for each of the parameters.

```{r Ex 6.3 nimble traceplots}

mvSamples <- mcmc.out$samples

#trace plots of beta1
plot(mvSamples[, c("beta1")])

#trace plots of base
plot(mvSamples[, c("base")])

#trace plots of RR
plot(mvSamples[, c("RR")])

#posterior summary of base
summary(mvSamples[, c("base")])

#posterior summary of RR
summary(mvSamples[, c("RR")])

```


### Stan {-}

```{r Ex 6.3 clean stan, echo = FALSE, include=FALSE, warning=FALSE, message= FALSE, results='hide'}

rm(list=ls())

```

Load `stan package` with options

```{r Ex 6.3 stan prelim load, class.source = 'foldable', message=FALSE, echo = TRUE, warning=FALSE}

library(rstan)

options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)

```


```{r engine='bash', comment='', echo = FALSE}
cat functions/Example6_3.stan
``` 

```{r Ex 6.3 stan load data, cache = TRUE, results='hide', message = FALSE, warning = FALSE}

data <- read.csv("data/DataExample53.csv", sep = ",")

stan_data <- list(
  N = nrow(data),
  E = data$exp_lungc65pls,
  X1 = as.vector(scale(data$k3)),
  X2 = as.vector(scale(data$k2)),
  Y = data$lungc65pls
)

Example6_3_Stan  <- stan(
  file = "functions/Example6_3.stan",
  data = stan_data,
  warmup = 5000,
  iter = 10000,
  chains = 3,
  include = TRUE
)

```

```{r Ex 6.3 stan traceplots}
rstan::traceplot(Example6_3_Stan,
                 pars = c("beta1", "base", "RR"))

stan_summary <- summary(Example6_3_Stan, pars = c("RR", "base"))
stan_summary$summary
```



